# ğŸ¯ SQL Mini Project â€“ Sales Data Insights  
*Day 14 of #30DaysDataAnalysisBeginnerChallenge*

## ğŸ“Œ Project Objective  
The goal of this mini-project was to apply core SQL concepts on a real-world-style dataset to extract business insights, practice advanced queries, and prepare for end-to-end data analysis workflows.  

---

## ğŸ—ƒï¸ Dataset  
The dataset simulates **sales transactions** and includes the following CSV files:
- Name: 100_Sales_Records.csv
- Source: GitHub Gist
- Records: 100 sales transactions


---

## ğŸ› ï¸ Tools Used  
- **MySQL** for database creation and querying  
- **Jupyter Notebook** to integrate SQL + Python  
- **SQLAlchemy & ipython-sql** to run SQL inside Jupyter

---

## âœ… Key Concepts Practiced  
The notebook includes examples using:

### ğŸ”¹ Aggregations
- Total revenue by country  
- Average revenue per country  
- Revenue per sales representative

### ğŸ”¹ Window Functions
- Rank regions by total profit using `RANK()`  
- Assign row numbers with `ROW_NUMBER()`  
- Compare values across rows using `LAG()` and `LEAD()`  

### ğŸ”¹ Joins
- `INNER JOIN` between `sales` and `products` for enriched reporting

### ğŸ”¹ Subqueries and CTEs
- Nested SELECT statements to extract top-performing orders  
- Common Table Expressions (CTEs) for cleaner modular queries

---

## ğŸ“ˆ Sample Questions Answered
- Which country generated the most revenue?
- Who were the top-performing sales reps?
- What are the top 5 most profitable orders?
- How does average revenue vary by region?

---

## ğŸ“š Learnings & Takeaways  
This project helped solidify SQL fundamentals by applying them in realistic business scenarios. Using **window functions**, **joins**, and **CTEs**, I was able to go beyond basic queries and extract layered insights from the data.

---

